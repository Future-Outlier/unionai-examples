{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local execution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, Annotated\n",
    "\n",
    "from pydantic import BaseModel\n",
    "from pathlib import Path\n",
    "import requests\n",
    "from urllib.parse import urljoin\n",
    "\n",
    "import flytekit as fl\n",
    "from flytekit.core.artifact import Artifact\n",
    "from flytekit.types.directory import FlyteDirectory\n",
    "from flytekit.types.file import FlyteFile\n",
    "from union.actor import ActorEnvironment\n",
    "\n",
    "TOGETHER_API_KEY = \"samhita-together-api-key\"\n",
    "\n",
    "actor = ActorEnvironment(\n",
    "    name=\"contextual-rag\",\n",
    "    replica_count=50,\n",
    "    ttl_seconds=120,\n",
    "    container_image=fl.ImageSpec(\n",
    "        name=\"contextual-rag\",\n",
    "        registry=\"ghcr.io/unionai-oss\",\n",
    "        packages=[\n",
    "            \"together==1.3.10\",\n",
    "            \"beautifulsoup4==4.12.3\",\n",
    "            \"bm25s==0.2.5\",\n",
    "            \"pydantic>2\",\n",
    "            \"chromadb==0.5.23\",\n",
    "            \"union>=0.1.117\",\n",
    "        ],\n",
    "    ),\n",
    "    secret_requests=[fl.Secret(key=TOGETHER_API_KEY)],\n",
    ")\n",
    "\n",
    "\n",
    "class Document(BaseModel):\n",
    "    idx: int\n",
    "    title: str\n",
    "    url: str\n",
    "    content: Optional[str] = None\n",
    "    chunks: Optional[list[str]] = None\n",
    "    prompts: Optional[list[str]] = None\n",
    "    contextual_chunks: Optional[list[str]] = None\n",
    "    tokens: Optional[list[list[int]]] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "@actor.task\n",
    "def parse_main_page(\n",
    "    base_url: str, articles_url: str, local: bool = False\n",
    ") -> list[Document]:\n",
    "    from bs4 import BeautifulSoup\n",
    "\n",
    "    assert base_url.endswith(\"/\"), f\"Base URL must end with a slash: {base_url}\"\n",
    "    response = requests.get(urljoin(base_url, articles_url))\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "    td_cells = soup.select(\"table > tr > td > table > tr > td\")\n",
    "    documents = []\n",
    "\n",
    "    idx = 0\n",
    "    for td in td_cells:\n",
    "        img = td.find(\"img\")\n",
    "        if img and int(img.get(\"width\", 0)) <= 15 and int(img.get(\"height\", 0)) <= 15:\n",
    "            a_tag = td.find(\"font\").find(\"a\") if td.find(\"font\") else None\n",
    "            if a_tag:\n",
    "                documents.append(\n",
    "                    Document(\n",
    "                        idx=idx, title=a_tag.text, url=urljoin(base_url, a_tag[\"href\"])\n",
    "                    )\n",
    "                )\n",
    "                idx += 1\n",
    "\n",
    "    if local:\n",
    "        return documents[:2]\n",
    "\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@actor.task\n",
    "def scrape_pg_essays(document: Document) -> Document:\n",
    "    from bs4 import BeautifulSoup\n",
    "\n",
    "    response = requests.get(document.url)\n",
    "    response.raise_for_status()\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    content = soup.find(\"font\")\n",
    "\n",
    "    text = None\n",
    "    if content:\n",
    "        text = \" \".join(content.get_text().split())\n",
    "    document.content = text\n",
    "    return document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@actor.task(cache=True, cache_version=\"0.2\")\n",
    "def create_chunks(document: Document, chunk_size: int, overlap: int) -> Document:\n",
    "    if document.content:\n",
    "        content_chunks = [\n",
    "            document.content[i : i + chunk_size]\n",
    "            for i in range(0, len(document.content), chunk_size - overlap)\n",
    "        ]\n",
    "        document.chunks = content_chunks\n",
    "    return document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@actor.task(cache=True, cache_version=\"0.4\")\n",
    "def generate_context(document: Document, model: str) -> Document:\n",
    "    from together import Together\n",
    "\n",
    "    CONTEXTUAL_RAG_PROMPT = \"\"\"\n",
    "Given the document below, we want to explain what the chunk captures in the document.\n",
    "\n",
    "{WHOLE_DOCUMENT}\n",
    "\n",
    "Here is the chunk we want to explain:\n",
    "\n",
    "{CHUNK_CONTENT}\n",
    "\n",
    "Answer ONLY with a succinct explanation of the meaning of the chunk in the context of the whole document above.\n",
    "\"\"\"\n",
    "\n",
    "    client = Together(api_key=fl.current_context().secrets.get(key=TOGETHER_API_KEY))\n",
    "\n",
    "    contextual_chunks = [\n",
    "        f\"{response.choices[0].message.content} {chunk}\"\n",
    "        for chunk in (document.chunks or [])\n",
    "        for response in [\n",
    "            client.chat.completions.create(\n",
    "                model=model,\n",
    "                messages=[\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": CONTEXTUAL_RAG_PROMPT.format(\n",
    "                            WHOLE_DOCUMENT=document.content,\n",
    "                            CHUNK_CONTENT=chunk,\n",
    "                        ),\n",
    "                    }\n",
    "                ],\n",
    "                temperature=1,\n",
    "            )\n",
    "        ]\n",
    "    ]\n",
    "\n",
    "    # Assign the contextual chunks back to the document\n",
    "    document.contextual_chunks = contextual_chunks if contextual_chunks else None\n",
    "    return document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chromadb import Documents, EmbeddingFunction, Embeddings\n",
    "from together import Together\n",
    "\n",
    "\n",
    "class TogetherEmbedding(EmbeddingFunction):\n",
    "    def __init__(self, model_name: str):\n",
    "        self.model = model_name\n",
    "        self.client = Together(\n",
    "            api_key=fl.current_context().secrets.get(key=TOGETHER_API_KEY)\n",
    "        )\n",
    "\n",
    "    def __call__(self, input: Documents) -> Embeddings:\n",
    "        outputs = self.client.embeddings.create(\n",
    "            input=input,\n",
    "            model=self.model,\n",
    "        )\n",
    "        return [x.embedding for x in outputs.data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "@actor.task(cache=True, cache_version=\"0.19\")\n",
    "def create_vector_index(\n",
    "    document: Document, model_api_string: str, local: bool = False\n",
    ") -> Document:\n",
    "    import os\n",
    "    import chromadb\n",
    "\n",
    "    if not local:\n",
    "        client = chromadb.HttpClient(\n",
    "            host=f\"http://contextual-rag-chroma-db-app.{os.getenv('FLYTE_INTERNAL_TASK_PROJECT')}-{os.getenv('FLYTE_INTERNAL_TASK_DOMAIN')}.svc.cluster.local\",  \n",
    "        ) # NOTE: Hard-coding the value for now; dynamic endpoint retrieval will be supported soon.\n",
    "    else:\n",
    "        client = chromadb.PersistentClient()\n",
    "\n",
    "    collection = client.get_or_create_collection(\n",
    "        name=\"paul-graham-collection\",\n",
    "        metadata={\"hnsw:space\": \"cosine\", \"hnsw:search_ef\": 50},\n",
    "        embedding_function=TogetherEmbedding(model_name=model_api_string),\n",
    "    )\n",
    "\n",
    "    if not document.contextual_chunks:\n",
    "        return document  # Exit early if there are no contextual chunks\n",
    "\n",
    "    ids = [\n",
    "        f\"id{document.idx}_{chunk_idx}\"\n",
    "        for chunk_idx, _ in enumerate(document.contextual_chunks)\n",
    "    ]\n",
    "    documents = [\n",
    "        chunk[:512]  # NOTE: Trimming the chunk for the embedding model's context window\n",
    "        for chunk in document.contextual_chunks\n",
    "    ]\n",
    "    metadatas = [{\"title\": document.title} for _ in document.contextual_chunks]\n",
    "\n",
    "    # Add to the collection\n",
    "    collection.upsert(ids=ids, documents=documents, metadatas=metadatas)\n",
    "\n",
    "    return document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "@actor.task(cache=True, cache_version=\"0.5\")\n",
    "def create_bm25s_index(documents: list[Document]) -> tuple[FlyteDirectory, FlyteFile]:\n",
    "    import json\n",
    "    import bm25s\n",
    "\n",
    "    # Prepare data for JSON\n",
    "    data = {\n",
    "        f\"id{doc_idx}_{chunk_idx}\": contextual_chunk\n",
    "        for doc_idx, document in enumerate(documents)\n",
    "        if document.contextual_chunks\n",
    "        for chunk_idx, contextual_chunk in enumerate(document.contextual_chunks)\n",
    "    }\n",
    "\n",
    "    retriever = bm25s.BM25(corpus=list(data.values()))\n",
    "    retriever.index(bm25s.tokenize(list(data.values())))\n",
    "\n",
    "    ctx = fl.current_context()\n",
    "    working_dir = Path(ctx.working_directory)\n",
    "    bm25s_index_dir = working_dir / \"bm25s_index\"\n",
    "    contextual_chunks_json = working_dir / \"contextual_chunks.json\"\n",
    "\n",
    "    retriever.save(str(bm25s_index_dir))\n",
    "\n",
    "    # Write the data to a JSON file\n",
    "    with open(contextual_chunks_json, \"w\", encoding=\"utf-8\") as json_file:\n",
    "        json.dump(data, json_file, indent=4, ensure_ascii=False)\n",
    "\n",
    "    return FlyteDirectory(path=bm25s_index_dir), FlyteFile(contextual_chunks_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samhitaalla/.pyenv/versions/contextual-rag-example/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['self', 'input'])\n",
      "odict_keys(['self', 'input'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RetrievalResults(vector_results=[['In the face of uncertainty, make choices that give you more options in the future, providing \"uncertainty-proof\" future flexibility. do in the face of uncertainty is to make choices that are uncertainty-proof. The less sure you are about what to do, the more important it is to choose options that give you more options in the future. I call this \"staying upwind.\" If you\\'re unsure w', 'The chunk advises considering options that are uncertain-proof by choosing \"upwind\" options - essentially, options that will give you more options or flexibility in the future, rather than limiting your options as much. This can be thought of as investing in areas with less่าง overlap or commitment, so you can more easily switch or pivot later if needed. ng upwind.\" If you\\'re unsure whether to major in math or economics, for example, choose math; math is upwind of economics in the sense that it will be easi', 'The speaker is criticizing the conventional advice of attending college and emphasizes that it only addresses the initial consideration of pursuing one\\'s interests, but does not provide guidance on finding information and overcoming doubts about one\\'s career path (\"or how hard this can be\").  this is good advice so far as it goes, but that\\'s where it usually ends. No one tells you how to figure out what to work on, or how hard this can be.What do you do in the face of uncertainty? Get more certainty. And pr', \"This chunk suggests engaging with activities you're interested in as a way to gather knowledge about your true interests, abilities, and potential for ambition, rather than waiting for certainty that might never come. bably the best way to do that is to try working on things you're interested in. That will get you more information about how interested you are in them, how good you are at them, and how much scope they offer for ambition.Don't wait. Don't wait till \", 'This chunk suggests choosing work that currently has more people around who are also interested in it, as it will provide more inspiration and less \"soul-sucking\" character, making it easier to continue doing the job in the long run.  from the outside. Whereas if you choose work you\\'re genuinely interested in, you\\'ll be surrounded mostly by other people who are genuinely interested in it, and that will make it extra inspiring. [3]The other thing you do in the face of uncertainty '], [\"The author explains that despite widespread pressure to write in many jobs, many people struggle with writing because it requires clear thinking, which is a fundamental and difficult skill to master.  need help writing.The reason so many people have trouble writing is that it's fundamentally difficult. To write well you have to think clearly, and thinking clearly is hard.And yet writing pervades many jobs, and the more prestigious the job, the mo\", \"The author suggests that, although writing skills may disappear, there will still be individuals who value and actively choose to develop their writing abilities, creating a distinction between those who write well and those who do not. nots. I know which half I want to be in, and I bet you do too.This situation is not unprecedented. In preindustrial times most people's jobs made them strong. Now if you want to be strong, you work out. So there are still strong people, but only thos\", 'The author suggests that a world where almost everyone can write easily, courtesy of AI, will lead to severe consequences. With most people unable to think critically and express themselves well, a substantial gap will emerge between \"good writers\" (those who possess true writing skills) and \"people who can\\'t write.\" This divide will be particularly perilous, as good writing skills are not just about productivity, but also about thinking ability.  ok writers, and people who can\\'t write, there will just be g', \"This chunk states that not writing (i.e., not thinking critically or deeply) can be deceptive, as it may give a false sense of thinking, and thus, a world where most people lack writing (and thus critical thinking skills) is more concerning than it initially seems.  better than Leslie Lamport did: If you're thinking without writing, you only think you're thinking. So a world divided into writes and write-nots is more dangerous than it sounds. It will be a world of thinks and think-nots. I know which half I \", \"This chunk states that writers have a unique insight into the struggles of the general population with writing, similar to how doctors know about moles and computer experts know about those who aren't familiar with computers. Writers have observed and learned about people who struggle with writing. u're a writer is how many people have trouble writing. Doctors know how many people have a mole they're worried about; people who are good at setting up computers know how many people aren't; writers know how man\"]], bm25s_results=[['In the face of uncertainty, make choices that give you more options in the future, providing \"uncertainty-proof\" future flexibility. do in the face of uncertainty is to make choices that are uncertainty-proof. The less sure you are about what to do, the more important it is to choose options that give you more options in the future. I call this \"staying upwind.\" If you\\'re unsure w', 'The speaker is criticizing the conventional advice of attending college and emphasizes that it only addresses the initial consideration of pursuing one\\'s interests, but does not provide guidance on finding information and overcoming doubts about one\\'s career path (\"or how hard this can be\").  this is good advice so far as it goes, but that\\'s where it usually ends. No one tells you how to figure out what to work on, or how hard this can be.What do you do in the face of uncertainty? Get more certainty. And probably the best way to do that ', 'This chunk suggests choosing work that currently has more people around who are also interested in it, as it will provide more inspiration and less \"soul-sucking\" character, making it easier to continue doing the job in the long run.  from the outside. Whereas if you choose work you\\'re genuinely interested in, you\\'ll be surrounded mostly by other people who are genuinely interested in it, and that will make it extra inspiring. [3]The other thing you do in the face of uncertainty ', \"The chunk explains that the inability to choose between pursuing one's passion or making money is often due to ignorance, and that people are usually unknowingly suffering from three types of ignorance: uncertainty about what makes them happy, the characteristics of different work, and their own capabilities.  which path to take, it's almost always due to ignorance. In fact you're usually suffering from three kinds of ignorance simultaneously: you don't know what makes you happy, what the various kinds of work are really like, or how well you could do the\", \"This chunk suggests that successful people often advise following one's passion, but this simplistic approach may not be applicable to everyone, particularly those who want to achieve great work. l how to do what they did, most will tell you that you have to work on what you're most interested in. And this is in fact true.That doesn't mean it's the right advice for everyone. Not everyone can do great work, or wants to. But if you do want to, \"], [\"This chunk highlights the author's concern that the increasing availability of AI-powered writing tools will lead to a significant shift, resulting in a future world where most people barely know how to write, and those who can write will hold onto the skills that facilitate higher levels of thinking. October 2024I'm usually reluctant to make predictions about technology, but I feel fairly confident about this one: in a couple decades there won't be many people who can write.One of the strangest things you learn if you're a writer is how many peop\", 'The chunk explains that prestigious jobs, which are often highly valued, require excessive writing, thereby increasing the pressure to write effectively. re prestigious the job, the more writing it tends to require.These two powerful opposing forces, the pervasive expectation of writing and the irreducible difficulty of doing it, create enormous pressure. This is why eminent professors often turn out ', \"The chunk suggests that as AI technology advances, the distinction between skilled writers (writes) and those who struggle to write (write-nots) will become increasingly pronounced, leading to a society where there will be two groups: those who can produce high-quality written work and those who cannot, with no middle ground. tes and write-nots. There will still be some people who can write. Some of us like it. But the middle ground between those who are good at writing and those who can't write at all will disappear. Instead of good writers, ok writers, and people who ca\", 'The author suggests that a world where almost everyone can write easily, courtesy of AI, will lead to severe consequences. With most people unable to think critically and express themselves well, a substantial gap will emerge between \"good writers\" (those who possess true writing skills) and \"people who can\\'t write.\" This divide will be particularly perilous, as good writing skills are not just about productivity, but also about thinking ability.  ok writers, and people who can\\'t write, there will just be good writers and people who can\\'t write.Is that so bad? Isn\\'t it common for skills to disappear when technology makes them obsolete? There aren\\'t many blacksmiths left, and it doesn\\'t seem t', \"The author explains that despite widespread pressure to write in many jobs, many people struggle with writing because it requires clear thinking, which is a fundamental and difficult skill to master.  need help writing.The reason so many people have trouble writing is that it's fundamentally difficult. To write well you have to think clearly, and thinking clearly is hard.And yet writing pervades many jobs, and the more prestigious the job, the mo\"]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "import functools\n",
    "from dataclasses import dataclass\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()  # Ensure the secret (together API key) is present in the .env file\n",
    "\n",
    "BM25Index = Artifact(name=\"bm25s-index\")\n",
    "ContextualChunksJSON = Artifact(name=\"contextual-chunks-json\")\n",
    "\n",
    "\n",
    "@fl.workflow\n",
    "def build_indices_wf(\n",
    "    base_url: str = \"https://paulgraham.com/\",\n",
    "    articles_url: str = \"articles.html\",\n",
    "    model_api_string: str = \"BAAI/bge-large-en-v1.5\",\n",
    "    chunk_size: int = 250,\n",
    "    overlap: int = 30,\n",
    "    model: str = \"meta-llama/Llama-3.2-3B-Instruct-Turbo\",\n",
    "    local: bool = True,\n",
    ") -> tuple[\n",
    "    Annotated[FlyteDirectory, BM25Index], Annotated[FlyteFile, ContextualChunksJSON]\n",
    "]:\n",
    "    tocs = parse_main_page(base_url=base_url, articles_url=articles_url, local=local)\n",
    "    scraped_content = fl.map_task(scrape_pg_essays)(document=tocs)\n",
    "    chunks = fl.map_task(\n",
    "        functools.partial(create_chunks, chunk_size=chunk_size, overlap=overlap)\n",
    "    )(document=scraped_content)\n",
    "    contextual_chunks = fl.map_task(functools.partial(generate_context, model=model))(\n",
    "        document=chunks\n",
    "    )\n",
    "    documents = fl.map_task(\n",
    "        functools.partial(\n",
    "            create_vector_index, model_api_string=model_api_string, local=local\n",
    "        )\n",
    "    )(document=contextual_chunks)\n",
    "    bm25s_index, contextual_chunks_json_file = create_bm25s_index(\n",
    "        documents=contextual_chunks\n",
    "    )\n",
    "    return bm25s_index, contextual_chunks_json_file\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class RetrievalResults:\n",
    "    vector_results: list[list[str]]\n",
    "    bm25s_results: list[list[str]]\n",
    "\n",
    "\n",
    "@fl.task\n",
    "def retrieve(\n",
    "    bm25s_index: FlyteDirectory,\n",
    "    contextual_chunks_data: FlyteFile,\n",
    "    model_api_string: str = \"BAAI/bge-large-en-v1.5\",\n",
    "    queries: list[str] = [\n",
    "        \"What to do in the face of uncertainty?\",\n",
    "        \"Why won't people write?\",\n",
    "    ],\n",
    ") -> RetrievalResults:\n",
    "    import json\n",
    "\n",
    "    import bm25s\n",
    "    import chromadb\n",
    "    import numpy as np\n",
    "\n",
    "    # Initialize ChromaDB client\n",
    "    client = chromadb.PersistentClient()\n",
    "\n",
    "    # Get the collection and set up the embedding function\n",
    "    collection_name = client.list_collections()[0].name\n",
    "    collection = client.get_collection(\n",
    "        collection_name,\n",
    "        embedding_function=TogetherEmbedding(model_name=model_api_string),\n",
    "    )\n",
    "\n",
    "    # Perform vector-based retrieval\n",
    "    vector_idx_result = collection.query(\n",
    "        query_texts=queries,\n",
    "        n_results=5,\n",
    "    )\n",
    "\n",
    "    # Load BM25S index\n",
    "    retriever = bm25s.BM25()\n",
    "    bm25_index = retriever.load(save_dir=bm25s_index.download())\n",
    "\n",
    "    # Load contextual chunk data\n",
    "    with open(contextual_chunks_data, \"r\", encoding=\"utf-8\") as json_file:\n",
    "        contextual_chunks_data_dict = json.load(json_file)\n",
    "\n",
    "    # Perform BM25S-based retrieval\n",
    "    bm25s_idx_result = bm25_index.retrieve(\n",
    "        query_tokens=bm25s.tokenize(queries),\n",
    "        k=5,\n",
    "        corpus=np.array(list(contextual_chunks_data_dict.values())),\n",
    "    )\n",
    "\n",
    "    # Return results as a dataclass\n",
    "    return RetrievalResults(\n",
    "        vector_results=vector_idx_result[\"documents\"],\n",
    "        bm25s_results=bm25s_idx_result.documents.tolist(),\n",
    "    )\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    bm25s_index, contextual_chunks_data = build_indices_wf()\n",
    "    results = retrieve(\n",
    "        bm25s_index=bm25s_index, contextual_chunks_data=contextual_chunks_data\n",
    "    )\n",
    "    print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remote execution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Login successful into demo.hosted.unionai.cloud\n"
     ]
    }
   ],
   "source": [
    "!union create login --auth device-flow --host demo.hosted.unionai.cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">22:43:15.714939 </span><span style=\"color: #808000; text-decoration-color: #808000\">WARNING </span> remote.py:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">286</span> - Jupyter notebook and interactive task  \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                </span>         support is still alpha.                                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m22:43:15.714939\u001b[0m\u001b[2;36m \u001b[0m\u001b[33mWARNING \u001b[0m remote.py:\u001b[1;36m286\u001b[0m - Jupyter notebook and interactive task  \n",
       "\u001b[2;36m                \u001b[0m         support is still alpha.                                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mImage samhitaalla/contextual-rag-chroma-db:O2I7a4vG4wQykMJAZVwR_A found. Skip building.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✨ Updating Application: contextual-rag-chroma-db-app with endpoint: \n",
       "<a href=\"https://morning-shape-d5d66.apps.demo.hosted.unionai.cloud\" target=\"_blank\"><span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://morning-shape-d5d66.apps.demo.hosted.unionai.cloud</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "✨ Updating Application: contextual-rag-chroma-db-app with endpoint: \n",
       "\u001b]8;id=164100;https://morning-shape-d5d66.apps.demo.hosted.unionai.cloud\u001b\\\u001b[4;94mhttps://morning-shape-d5d66.apps.demo.hosted.unionai.cloud\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from flytekit.configuration import Config\n",
    "from union.app import Endpoint\n",
    "from union.remote._app_remote import AppRemote\n",
    "\n",
    "load_dotenv()  # Ensure you add REGISTRY to the .env file.\n",
    "\n",
    "\n",
    "# Ensure Chroma DB is up and running\n",
    "chroma_app = Endpoint(\n",
    "    name=\"contextual-rag-chroma-db-app\",\n",
    "    container_image=fl.ImageSpec(\n",
    "        name=\"contextual-rag-chroma-db\",\n",
    "        registry=os.getenv(\"REGISTRY\"),\n",
    "        packages=[\"union-runtime>=0.1.5\", \"chromadb\"],\n",
    "    ),\n",
    "    limits=fl.Resources(cpu=\"3\", mem=\"5Gi\"),\n",
    "    port=8080,\n",
    "    min_replicas=1,\n",
    "    max_replicas=1,\n",
    "    command=[\"chroma\", \"run\", \"--port\", \"8080\"],\n",
    ")\n",
    "\n",
    "app_remote = AppRemote(\n",
    "    config=Config.for_endpoint(endpoint=\"demo.hosted.unionai.cloud\"),\n",
    "    project=\"demo\",\n",
    "    domain=\"development\",\n",
    ")\n",
    "\n",
    "app_remote.create_or_update(chroma_app)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">22:43:22.059485 </span><span style=\"color: #808000; text-decoration-color: #808000\">WARNING </span> remote.py:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">286</span> - Jupyter notebook and interactive task  \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                </span>         support is still alpha.                                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m22:43:22.059485\u001b[0m\u001b[2;36m \u001b[0m\u001b[33mWARNING \u001b[0m remote.py:\u001b[1;36m286\u001b[0m - Jupyter notebook and interactive task  \n",
       "\u001b[2;36m                \u001b[0m         support is still alpha.                                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from union.remote import UnionRemote\n",
    "from flytekit.configuration import Config\n",
    "\n",
    "remote = UnionRemote(\n",
    "    config=Config.for_endpoint(endpoint=\"demo.hosted.unionai.cloud\"),\n",
    "    default_project=\"demo\",\n",
    "    default_domain=\"development\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mImage ghcr.io/unionai-oss/contextual-rag:wFn1_Qnfqo7_7HcL041hyA found. Skip building.\u001b[0m\n",
      "https://demo.hosted.unionai.cloud/console/projects/demo/domains/development/executions/a4wcn6p2tgkqbzf88cvr\n"
     ]
    }
   ],
   "source": [
    "indices_execution = remote.execute(build_indices_wf, inputs={\"local\": False})\n",
    "print(indices_execution.execution_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ───────────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">9</span>                                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 9 registered_lp = remote.register_launch_plan(                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/Users/samhitaalla/.pyenv/versions/contextual-rag-example/lib/python3.12/site-packages/flytekit/remote/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">remote.p</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">y</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1259</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">register_launch_plan</span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1259 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>_, _, _, module_file = <span style=\"font-weight: bold; text-decoration: underline\">extract_task_module(entity)</span>                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/Users/samhitaalla/.pyenv/versions/contextual-rag-example/lib/python3.12/site-packages/flytekit/core/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">tracker.py</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> :<span style=\"color: #0000ff; text-decoration-color: #0000ff\">358</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">extract_task_module</span>                                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>358 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>mod, mod_name, name = <span style=\"font-weight: bold; text-decoration: underline\">_task_module_from_callable(f)</span>                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/Users/samhitaalla/.pyenv/versions/contextual-rag-example/lib/python3.12/site-packages/flytekit/core/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">tracker.py</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> :<span style=\"color: #0000ff; text-decoration-color: #0000ff\">337</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_task_module_from_callable</span>                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>337 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>name = <span style=\"font-weight: bold; text-decoration: underline\">f.</span><span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; text-decoration: underline\">__name__</span>.split(<span style=\"color: #808000; text-decoration-color: #808000\">\".\"</span>)[-<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>]                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">AttributeError: </span><span style=\"color: #008000; text-decoration-color: #008000\">'LaunchPlan'</span> object has no attribute <span style=\"color: #008000; text-decoration-color: #008000\">'__name__'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m──────────────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m9\u001b[0m                                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 9 registered_lp = remote.register_launch_plan(                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/Users/samhitaalla/.pyenv/versions/contextual-rag-example/lib/python3.12/site-packages/flytekit/remote/\u001b[0m\u001b[1;33mremote.p\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[1;33my\u001b[0m:\u001b[94m1259\u001b[0m in \u001b[92mregister_launch_plan\u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1259 \u001b[2m│   │   │   \u001b[0m_, _, _, module_file = \u001b[1;4mextract_task_module(entity)\u001b[0m                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/Users/samhitaalla/.pyenv/versions/contextual-rag-example/lib/python3.12/site-packages/flytekit/core/\u001b[0m\u001b[1;33mtracker.py\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m :\u001b[94m358\u001b[0m in \u001b[92mextract_task_module\u001b[0m                                                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m358 \u001b[2m│   │   \u001b[0mmod, mod_name, name = \u001b[1;4m_task_module_from_callable(f)\u001b[0m                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/Users/samhitaalla/.pyenv/versions/contextual-rag-example/lib/python3.12/site-packages/flytekit/core/\u001b[0m\u001b[1;33mtracker.py\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m :\u001b[94m337\u001b[0m in \u001b[92m_task_module_from_callable\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m337 \u001b[2m│   \u001b[0mname = \u001b[1;4mf.\u001b[0m\u001b[1;4;91m__name__\u001b[0m.split(\u001b[33m\"\u001b[0m\u001b[33m.\u001b[0m\u001b[33m\"\u001b[0m)[-\u001b[94m1\u001b[0m]                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mAttributeError: \u001b[0m\u001b[32m'LaunchPlan'\u001b[0m object has no attribute \u001b[32m'__name__'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lp = fl.LaunchPlan.get_or_create(\n",
    "    build_indices_wf,\n",
    "    name=\"vector_db_ingestion\",\n",
    "    schedule=fl.CronSchedule(\n",
    "        schedule=\"0 1 * * *\"\n",
    "    ),  # Run every day to update the databases\n",
    ")\n",
    "\n",
    "registered_lp = remote.register_launch_plan(\n",
    "    entity=lp, version=\"v1\"\n",
    ")  # Issue: https://github.com/flyteorg/flyte/issues/6062\n",
    "remote.activate_launchplan(registered_lp.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy apps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mImage samhitaalla/contextual-rag-fastapi:_xIA2c7PUskwr4MKatBNTQ found. Skip building.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✨ Updating Application: contextual-rag-fastapi-app with endpoint: \n",
       "<a href=\"https://lively-water-07ddd.apps.demo.hosted.unionai.cloud\" target=\"_blank\"><span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://lively-water-07ddd.apps.demo.hosted.unionai.cloud</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "✨ Updating Application: contextual-rag-fastapi-app with endpoint: \n",
       "\u001b]8;id=135070;https://lively-water-07ddd.apps.demo.hosted.unionai.cloud\u001b\\\u001b[4;94mhttps://lively-water-07ddd.apps.demo.hosted.unionai.cloud\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mImage samhitaalla/contextual-rag-gradio:OeZ_3noh7WUu8i4JAnEzVQ found. Skip building.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✨ Updating Application: contextual-rag-gradio-app with endpoint: \n",
       "<a href=\"https://plain-star-a9f2d.apps.demo.hosted.unionai.cloud\" target=\"_blank\"><span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://plain-star-a9f2d.apps.demo.hosted.unionai.cloud</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "✨ Updating Application: contextual-rag-gradio-app with endpoint: \n",
       "\u001b]8;id=98771;https://plain-star-a9f2d.apps.demo.hosted.unionai.cloud\u001b\\\u001b[4;94mhttps://plain-star-a9f2d.apps.demo.hosted.unionai.cloud\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from union.app import App, Endpoint, Input\n",
    "\n",
    "fastapi_app = Endpoint(\n",
    "    name=\"contextual-rag-fastapi-app\",\n",
    "    inputs=[\n",
    "        Input(\n",
    "            name=\"bm25s_index\",\n",
    "            value=BM25Index.query(),\n",
    "            auto_download=True,\n",
    "            env_name=\"BM25S_INDEX\",\n",
    "        ),\n",
    "        Input(\n",
    "            name=\"contextual_chunks_json\",\n",
    "            value=ContextualChunksJSON.query(),\n",
    "            auto_download=True,\n",
    "            env_name=\"CONTEXTUAL_CHUNKS_JSON\",\n",
    "        ),\n",
    "        Input(\n",
    "            name=\"chroma_db_endpoint\",\n",
    "            value=chroma_app.query_endpoint(public=False),\n",
    "            env_name=\"CHROMA_DB_ENDPOINT\",\n",
    "        ),\n",
    "    ],\n",
    "    container_image=fl.ImageSpec(\n",
    "        name=\"contextual-rag-fastapi\",\n",
    "        registry=os.getenv(\"REGISTRY\"),\n",
    "        packages=[\n",
    "            \"together\",\n",
    "            \"bm25s\",\n",
    "            \"chromadb\",\n",
    "            \"fastapi[standard]\",\n",
    "            \"union-runtime>=0.1.5\",\n",
    "        ],\n",
    "    ),\n",
    "    limits=fl.Resources(cpu=\"3\", mem=\"10Gi\"),\n",
    "    port=8080,\n",
    "    include=[\"./fastapi_app.py\"],\n",
    "    command=[\"fastapi\", \"dev\", \"--port\", \"8080\"],\n",
    "    min_replicas=1,\n",
    "    max_replicas=1,\n",
    ")\n",
    "\n",
    "\n",
    "gradio_app = App(\n",
    "    name=\"contextual-rag-gradio-app\",\n",
    "    inputs=[\n",
    "        Input(\n",
    "            name=\"fastapi_endpoint\",\n",
    "            value=fastapi_app.query_endpoint(public=False),\n",
    "            env_name=\"FASTAPI_ENDPOINT\",\n",
    "        )\n",
    "    ],\n",
    "    container_image=fl.ImageSpec(\n",
    "        name=\"contextual-rag-gradio\",\n",
    "        registry=os.getenv(\"REGISTRY\"),\n",
    "        packages=[\"gradio\", \"union-runtime>=0.1.5\"],\n",
    "    ),\n",
    "    limits=fl.Resources(cpu=\"1\", mem=\"1Gi\"),\n",
    "    port=8080,\n",
    "    include=[\"./gradio_app.py\"],\n",
    "    command=[\n",
    "        \"python\",\n",
    "        \"gradio_app.py\",\n",
    "    ],\n",
    "    min_replicas=1,\n",
    "    max_replicas=1,\n",
    ")\n",
    "\n",
    "app_remote.create_or_update(fastapi_app)\n",
    "app_remote.create_or_update(gradio_app)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">⏳ Stopping Application: contextual-rag-fastapi-app\n",
       "</pre>\n"
      ],
      "text/plain": [
       "⏳ Stopping Application: contextual-rag-fastapi-app\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">⏳ Stopping Application: contextual-rag-gradio-app\n",
       "</pre>\n"
      ],
      "text/plain": [
       "⏳ Stopping Application: contextual-rag-gradio-app\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# app_remote.stop(name=\"contextual-rag-fastapi-app\")\n",
    "# app_remote.stop(name=\"contextual-rag-gradio-app\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "contextual-rag-example",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
